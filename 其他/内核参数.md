## 内核参数
---
### 网络部分
> **TCP连接重传机制**
  - 这个内核参数是控制，在 TCP 连接建立的情况下，超时重传的最大次数。
    ```bash
    net.ipv4.tcp_retries2=15
    ```
> **TCP keepalive 机制具体**
  - 定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。
  - 在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：
    ```bash
    # 表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制
    net.ipv4.tcp_keepalive_time=7200
    # 表示每次检测间隔 75 秒
    net.ipv4.tcp_keepalive_intvl=75
    # 表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。
    net.ipv4.tcp_keepalive_probes=9
    也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。
    ```

```bash
kernel.panic = 5
# tcp backlog队列
net.core.somaxconn = 262144
net.ipv4.tcp_abort_on_overflow = 0
# syn+ack包尝试发送的次数。每次重试等待时间为2的幂次。最后一次为等待时长31秒。最终超时连接需要经历63秒
net.ipv4.tcp_synack_retries = 5
# 初始化tcp连接时，尝试发送syn包的次数。每次重试等待时间为2的幂次。最后一次为等待时长63秒。最终超时连接需要经历127秒
net.ipv4.tcp_syn_retries = 6

# tcp 半队列大小，但需要需要listen backlog、smaxconn、max_syn_backlog同时调整，会影响半队列大小
net.ipv4.tcp_max_syn_backlog = 262144

# tcp ipv4的调整
net.ipv4.tcp_syncookies = 1
net.ipv4.ip_local_port_range = 10000 65000
net.ipv4.tcp_timestamps = 1
net.ipv4.tcp_tw_reuse = 0
net.ipv4.tcp_tw_recycle = 0

# 以下是为未了解的参数
net.ipv4.netfilter.ip_conntrack_max
net.ipv4.tcp_slow_start_after_idle
net.ipv4.route.gc_timeout
net.ipv4.tcp_fastopen
net.ipv4.icmp_ignore_bogus_error_responses
# 网络设备接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目？
net.core.netdev_max_backlog = 262144
# 最大的TCP 数据接收缓冲（字节）？
net.core.rmem_max = 8388608
# 最大的TCP 数据发送缓冲（字节）？
net.core.wmem_max = 8388608




# 关闭IPv6
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1

```

### file-max / file-nr
> cat /proc/sys/fs/file-max；这个文件决定了系统级别所有进程可以打开的文件描述符的数量限制，如果内核中遇到VFS: file-max limit <number> reached的信息，那么就提高这个值。

> cat /proc/sys/fs/file-nr；这个是一个状态指示的文件，一共三个值，第一个代表全局已经分配的文件描述符数量，第二个代表自由的文件描述符（待重新分配的），第三个代表总的文件描述符的数量。

“进程每打开一个文件（linux下一切皆文件，包括socket），都会消耗一定的内存资源。如果有不怀好心的人启动一个进程来无限的创建和打开新的文件，会让服务器崩溃。所以linux系统出于安全角度的考虑，在多个位置都限制了可打开的文件描述符的数量，包括系统级、用户级、进程级。这三个限制的含义和修改方式如下：”

系统级：当前系统可打开的最大数量，通过fs.file-max参数可修改

用户级：指定用户可打开的最大数量，修改/etc/security/limits.conf

进程级：单个进程可打开的最大数量，通过fs.nr_open参数可修改


“TCP分配发送缓存区的大小受参数net.ipv4.tcp_wmem配置影响。”

$ sysctl -a | grep wmem
net.ipv4.tcp_wmem = 4096 65536 8388608
net.core.wmem_default = 212992
net.core.wmem_max = 8388608



### 桥接参数
- bridge-nf-call-arptables
  - 0: 关闭
  - 1: 将桥接的 ARP 流量传递到 arptables 的 FORWARD 链。
- bridge-nf-call-iptables
  - 0: 关闭
  - 1: 将桥接的 IPv4 流量传递到 iptables 的链。
### arp参数
- arp_ignore: 定义不同的模式来发送回复以响应接收到的解析本地目标 IP 地址的 ARP 请求
  - 0：响应任意网卡上接收到的对本机IP地址的arp请求（包括环回网卡上的地址），而不管该目的IP是否在接收网卡上。
  - 1：只响应目的IP地址为接收网卡上的本地地址的arp请求。
  - 2：只响应目的IP地址为接收网卡上的本地地址的arp请求，并且arp请求的源IP必须和接收网卡同网段。
  - 3：如果ARP请求数据包所请求的IP地址对应的本地地址其作用域（scope）为主机（host），则不回应ARP响应数据包，如果作用域为全局（global）或链路（link），则回应ARP响应数据包。
  - 4~7：保留未使用
  - 8：不回应所有的arp请求
- arp_announce: 作用是控制系统在对外发送arp请求时，如何选择arp请求数据包的源IP地址。（比如系统准备通过网卡发送一个数据包a，这时数据包a的源IP和目的IP一般都是知道的，而根据目的IP查询路由表，发送网卡也是确定的，故源MAC地址也是知道的，这时就差确定目的MAC地址了。而想要获取目的IP对应的目的MAC地址，就需要发送arp请求。arp请求的目的IP自然就是想要获取其MAC地址的IP，而arp请求的源IP是什么呢？ 可能第一反应会以为肯定是数据包a的源IP地址，但是这个也不是一定的，arp请求的源IP是可以选择的，控制这个地址如何选择就是arp_announce的作用）
  - 0: 使用任何本地地址，在任何接口上配置
  - 1: 尽量避免不在目标地址中的本地地址此接口的子网
  - 2: 始终为此目标使用最佳本地地址

---
### 参考信息
- [阿里云面试：拔掉网线后， 原本的 TCP 连接还存在吗？](https://mp.weixin.qq.com/s/0YFsUWL6e9r_aDrCZeTK3w)
- [内核sysctl手册说明](https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt)
- [内核参数查询](https://sysctl-explorer.net/)
- [Linux内核参数之arp_ignore和arp_announce](https://www.jianshu.com/p/734640384fda)
- [再聊 TCP backlog](https://mp.weixin.qq.com/s/cgE7cwyn2LwkXP7G0cxyPg)
- [面试官：换人！他连 TCP 这几个参数都不懂](https://segmentfault.com/a/1190000022874344)